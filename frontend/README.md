# FullyRAG Frontend Application

**Streamlit-based chat interface for FullyRAG - Interactive AI research assistant**

This is the frontend application for FullyRAG, providing a beautiful and intuitive chat interface for interacting with the AI research assistant. Built with Streamlit, it offers real-time streaming responses, PDF viewing with annotations, conversation management, and more.

## ğŸš€ Features

- **Interactive Chat Interface**: Clean, responsive chat UI with streaming responses
- **PDF Viewer with Annotations**: View PDFs with automatically highlighted relevant sections
- **Multi-Language Support**: Configurable language settings and display texts
- **Conversation Management**: Create, view, and delete conversation threads
- **User Authentication**: Secure login system (optional)
- **Feedback System**: Rate responses and provide feedback
- **File Upload**: Upload documents directly in the chat
- **Data Visualization**: View charts and graphs generated by the backend

## ğŸ“‹ Prerequisites

- Python 3.12 or higher
- Running FullyRAG Backend Service (see backend README)
- (Optional) Docker and Docker Compose

## ğŸ”§ Installation

### Option 1: Local Development with Python

1. **Clone and navigate to the frontend directory**
   ```bash
   cd frontend
   ```

2. **Create a virtual environment and install dependencies**
   ```bash
   pip install uv
   uv sync --frozen
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your backend URL and settings
   ```

4. **Ensure backend is running**
   The backend service should be running at the URL specified in `AGENT_URL` (default: `http://localhost:8080`)

5. **Run the application**
   ```bash
   streamlit run src/streamlit-app.py
   ```

   The app will be available at `http://localhost:8501`

### Option 2: Docker (recommended for full stack)

1. **Configure environment (repo root)**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

2. **Start the stack from repo root**
   ```bash
   docker compose -f compose.yaml up --build -d
   ```

   The app will be available at `http://localhost:8501` (backend at `http://localhost:8080`).

3. **View logs**
   ```bash
   docker compose -f compose.yaml logs -f streamlit-app
   ```

## âš™ï¸ Configuration

Key environment variables (see `.env.example` for full list):

### Backend Connection
- `AGENT_URL`: Backend service URL (default: `http://localhost:8080`)
- `AUTH_SECRET`: Shared secret for backend authentication (must match backend)

### Authentication
- `NO_AUTH`: Disable authentication for development (default: `False`)

### Display Configuration
- `DISPLAY_TEXTS_JSON_PATH`: Path to customizable UI texts JSON file

## ğŸ¨ Customization

### Display Texts

Customize all UI text, labels, and messages by editing the display texts JSON file:

```json
{
  "LOGO": "media/fullyrag.png",
  "BIG_LOGO": true,
  "LOGOUT": "Logout",
  "FEEDBACK": "Feedback",
  "messages": {
    "welcome": "Welcome to FullyRAG!",
    "chat_placeholder": "Ask me anything..."
  }
}
```

### Styling

Streamlit configuration can be customized in `.streamlit/config.toml`:

```toml
[theme]
primaryColor = "#FF4B4B"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
font = "sans serif"
```

### Languages

Multi-language support is available through the `display_texts.py` module. Add new languages by extending the language mappings.

## ğŸ“ Project Structure

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ client/              # Backend API client
â”‚   â”‚   â””â”€â”€ client.py        # AgentClient for API communication
â”‚   â”œâ”€â”€ frontend/            # UI components
â”‚   â”‚   â”œâ”€â”€ chat.py          # Main chat interface
â”‚   â”‚   â”œâ”€â”€ feedback.py      # Feedback page
â”‚   â”‚   â”œâ”€â”€ user.py          # User profile/logout
â”‚   â”‚   â””â”€â”€ pdf_viewer_with_annotations.py  # PDF viewer
â”‚   â”œâ”€â”€ schema/              # Shared data models
â”‚   â”œâ”€â”€ streamlit-app.py     # Main application entry point
â”‚   â”œâ”€â”€ display_texts.py     # UI text management
â”‚   â”œâ”€â”€ multilanguage_css.py # Multi-language CSS
â”‚   â””â”€â”€ auth_helpers.py      # Authentication utilities
â”œâ”€â”€ media/                   # Images, logos, assets
â”œâ”€â”€ .streamlit/              # Streamlit configuration
â”œâ”€â”€ (built via repo-root docker/Dockerfile.app and compose.yaml)
â”œâ”€â”€ pyproject.toml           # Python dependencies
â””â”€â”€ README.md               # This file
```

## ğŸ¯ Usage

### Starting a Conversation

1. Open the app in your browser
2. Log in (if authentication is enabled)
3. Type your question in the chat input
4. Receive streaming responses from the AI

### Viewing PDFs

1. When the AI references a document, click on the PDF link
2. The PDF viewer will open with relevant sections highlighted
3. Use the navigation tools to explore the document

### Managing Conversations

- **New Conversation**: Click the "+" button in the sidebar
- **View History**: Select previous conversations from the sidebar
- **Delete Conversation**: Click the delete icon next to a conversation

### Providing Feedback

1. After receiving a response, use the star rating system
2. Optionally add written feedback
3. Submit to help improve the system

## ğŸ”Œ Backend Communication

The frontend communicates with the backend using the `AgentClient` class:

```python
from client import AgentClient

# Initialize client
client = AgentClient(base_url="http://localhost:8080")

# Stream a response
async for message in client.astream(
    message="What is machine learning?",
    thread_id="conversation-123"
):
    print(message)
```

## ğŸ› Troubleshooting

### Cannot Connect to Backend
- Verify backend is running: `curl http://localhost:8080/health`
- Check `AGENT_URL` in `.env` matches backend address
- Ensure no firewall is blocking the connection

### Authentication Issues
- Verify `AUTH_SECRET` matches between frontend and backend
- Check if `NO_AUTH=True` for development mode
- Clear browser cache and cookies

### Streamlit Port Already in Use
- Change port: `streamlit run src/streamlit-app.py --server.port 8502`
- Or stop the process using port 8501

### PDF Viewer Not Working
- Ensure backend has access to PDF files
- Check browser console for JavaScript errors
- Verify `streamlit-pdf-viewer` package is installed

## ğŸ§ª Development

### Running in Development Mode

```bash
# With auto-reload
streamlit run src/streamlit-app.py --server.runOnSave true
```

### Testing Components

```bash
# Run tests
pytest tests/

# Run with coverage
pytest --cov=src tests/
```

## ğŸ“Š Features in Detail

### Chat Interface
- Real-time streaming responses
- Message history with timestamps
- File attachment support
- Code syntax highlighting
- Markdown rendering

### PDF Viewer
- Contextual highlighting of relevant blocks
- Zoom and navigation controls
- Annotation layer over original PDF
- Mobile-responsive design

### Conversation Management
- Automatic title generation
- Conversation search
- Export conversation history
- Delete with confirmation

## ğŸ”’ Security

- All backend communication uses HTTPS in production
- Authentication tokens are stored securely
- User sessions are managed by Streamlit
- No sensitive data is stored in browser localStorage

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or submit a pull request.

## ğŸ“§ Support

For issues and questions, please open a GitHub issue or contact the maintainers.

## ğŸ”— Related

- [FullyRAG Backend](../backend/README.md) - API service documentation
- [Streamlit Documentation](https://docs.streamlit.io/)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
